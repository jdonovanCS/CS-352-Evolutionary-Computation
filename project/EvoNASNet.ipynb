{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Regularized evolution as described in:\n",
    "Real, E., Aggarwal, A., Huang, Y., and Le, Q. V.\n",
    "Regularized Evolution for Image Classifier Architecture Search.\n",
    "In Proceedings of the Conference on Artificial Intelligence (AAAIâ€™19)\n",
    "\n",
    "The code is based one the original regularized evolution open-source implementation:\n",
    "https://colab.research.google.com/github/google-research/google-research/blob/master/evolution/regularized_evolution_algorithm/regularized_evolution.ipynb\n",
    "\n",
    "NOTE: This script has certain deviations from the original code owing to the search space of the benchmarks used:\n",
    "1) The fitness function is not accuracy but error and hence the negative error is being maximized.\n",
    "2) The architecture is a ConfigSpace object that defines the model architecture parameters.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ConfigSpace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b08ebeb66e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mConfigSpace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ConfigSpace'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import ConfigSpace\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# from tabular_benchmarks import FCNetProteinStructureBenchmark, FCNetSliceLocalizationBenchmark,\\\n",
    "#     FCNetNavalPropulsionBenchmark, FCNetParkinsonsTelemonitoringBenchmark\n",
    "from tabular_benchmarks import NASCifar10A, NASCifar10B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\"A class representing a model.\n",
    "\n",
    "    It holds two attributes: `arch` (the simulated architecture) and `accuracy`\n",
    "    (the simulated accuracy / fitness). See Appendix C for an introduction to\n",
    "    this toy problem.\n",
    "\n",
    "    In the real case of neural networks, `arch` would instead hold the\n",
    "    architecture of the normal and reduction cells of a neural network and\n",
    "    accuracy would be instead the result of training the neural net and\n",
    "    evaluating it on the validation set.\n",
    "\n",
    "    We do not include test accuracies here as they are not used by the algorithm\n",
    "    in any way. In the case of real neural networks, the test accuracy is only\n",
    "    used for the purpose of reporting / plotting final results.\n",
    "\n",
    "    In the context of evolutionary algorithms, a model is often referred to as\n",
    "    an \"individual\".\n",
    "\n",
    "    Attributes:  (as in the original code)\n",
    "      arch: the architecture as an int representing a bit-string of length `DIM`.\n",
    "          As a result, the integers are required to be less than `2**DIM`. They\n",
    "          can be visualized as strings of 0s and 1s by calling `print(model)`,\n",
    "          where `model` is an instance of this class.\n",
    "      accuracy:  the simulated validation accuracy. This is the sum of the\n",
    "          bits in the bit-string, divided by DIM to produce a value in the\n",
    "          interval [0.0, 1.0]. After that, a small amount of Gaussian noise is\n",
    "          added with mean 0.0 and standard deviation `NOISE_STDEV`. The resulting\n",
    "          number is clipped to within [0.0, 1.0] to produce the final validation\n",
    "          accuracy of the model. A given model will have a fixed validation\n",
    "          accuracy but two models that have the same architecture will generally\n",
    "          have different validation accuracies due to this noise. In the context\n",
    "          of evolutionary algorithms, this is often known as the \"fitness\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.arch = None\n",
    "        self.accuracy = None\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints a readable version of this bitstring.\"\"\"\n",
    "        return '{0:b}'.format(self.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(config):\n",
    "    y, cost = b.objective_function(config)\n",
    "    # returns negative error (similar to maximizing accuracy)\n",
    "    return -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_architecture():\n",
    "    config = cs.sample_configuration()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_arch(parent_arch):\n",
    "    # pick random parameter\n",
    "    dim = np.random.randint(len(cs.get_hyperparameters()))\n",
    "    hyper = cs.get_hyperparameters()[dim]\n",
    "\n",
    "    if type(hyper) == ConfigSpace.OrdinalHyperparameter:\n",
    "        choices = list(hyper.sequence)\n",
    "    else:\n",
    "        choices = list(hyper.choices)\n",
    "    # drop current values from potential choices\n",
    "    choices.remove(parent_arch[hyper.name])\n",
    "\n",
    "    # flip parameter\n",
    "    idx = np.random.randint(len(choices))\n",
    "\n",
    "    child_arch = deepcopy(parent_arch)\n",
    "    child_arch[hyper.name] = choices[idx]\n",
    "    return child_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_evolution(cycles, population_size, sample_size):\n",
    "    \"\"\"Algorithm for regularized evolution (i.e. aging evolution).\n",
    "\n",
    "    Follows \"Algorithm 1\" in Real et al. \"Regularized Evolution for Image\n",
    "    Classifier Architecture Search\".\n",
    "\n",
    "    Args:\n",
    "      cycles: the number of cycles the algorithm should run for.\n",
    "      population_size: the number of individuals to keep in the population.\n",
    "      sample_size: the number of individuals that should participate in each\n",
    "          tournament.\n",
    "\n",
    "    Returns:\n",
    "      history: a list of `Model` instances, representing all the models computed\n",
    "          during the evolution experiment.\n",
    "    \"\"\"\n",
    "    population = collections.deque()\n",
    "    history = []  # Not used by the algorithm, only used to report results.\n",
    "\n",
    "    # Initialize the population with random models.\n",
    "    while len(population) < population_size:\n",
    "        model = Model()\n",
    "        model.arch = random_architecture()\n",
    "        model.accuracy = train_and_eval(model.arch)\n",
    "        population.append(model)\n",
    "        history.append(model)\n",
    "\n",
    "    # Carry out evolution in cycles. Each cycle produces a model and removes\n",
    "    # another.\n",
    "    while len(history) < cycles:\n",
    "        # Sample randomly chosen models from the current population.\n",
    "        sample = []\n",
    "        while len(sample) < sample_size:\n",
    "            # Inefficient, but written this way for clarity. In the case of neural\n",
    "            # nets, the efficiency of this line is irrelevant because training neural\n",
    "            # nets is the rate-determining step.\n",
    "            candidate = random.choice(list(population))\n",
    "            sample.append(candidate)\n",
    "\n",
    "        # The parent is the best model in the sample.\n",
    "        parent = max(sample, key=lambda i: i.accuracy)\n",
    "\n",
    "        # Create the child model and store it.\n",
    "        child = Model()\n",
    "        child.arch = mutate_arch(parent.arch)\n",
    "        child.accuracy = train_and_eval(child.arch)\n",
    "        population.append(child)\n",
    "        history.append(child)\n",
    "\n",
    "        # Remove the oldest model.\n",
    "        population.popleft()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file... This may take a few minutes...\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\nasbench-1.0-py3.7.egg\\nasbench\\api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Loaded dataset in 644 seconds\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--run_id', default=0, type=int, nargs='?', help='unique number to identify this run')\n",
    "# parser.add_argument('--benchmark', default=\"protein_structure\", type=str, nargs='?', help='specifies the benchmark')\n",
    "# parser.add_argument('--n_iters', default=100, type=int, nargs='?', help='number of iterations for optimization method')\n",
    "# parser.add_argument('--output_path', default=\"./\", type=str, nargs='?',\n",
    "#                     help='specifies the path where the results will be saved')\n",
    "# parser.add_argument('--data_dir', default=\"./\", type=str, nargs='?', help='specifies the path to the tabular data')\n",
    "# parser.add_argument('--pop_size', default=100, type=int, nargs='?', help='population size')\n",
    "# parser.add_argument('--sample_size', default=10, type=int, nargs='?', help='sample_size')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "run_id = 0\n",
    "benchmark = 'nas_cifar10a'\n",
    "n_iters = 100\n",
    "output_path = './'\n",
    "data_dir = './'\n",
    "pop_size = 100\n",
    "sample_size = 10\n",
    "\n",
    "if benchmark == \"nas_cifar10a\":\n",
    "    b = NASCifar10A(data_dir=data_dir)\n",
    "\n",
    "elif benchmark == \"nas_cifar10b\":\n",
    "    b = NASCifar10B(data_dir=data_dir)\n",
    "\n",
    "elif benchmark == \"protein_structure\":\n",
    "    b = FCNetProteinStructureBenchmark(data_dir=data_dir)\n",
    "\n",
    "elif benchmark == \"slice_localization\":\n",
    "    b = FCNetSliceLocalizationBenchmark(data_dir=data_dir)\n",
    "\n",
    "elif benchmark == \"naval_propulsion\":\n",
    "    b = FCNetNavalPropulsionBenchmark(data_dir=data_dir)\n",
    "\n",
    "elif benchmark == \"parkinsons_telemonitoring\":\n",
    "    b = FCNetParkinsonsTelemonitoringBenchmark(data_dir=data_dir)\n",
    "\n",
    "output_path = os.path.join(output_path, \"regularized_evolution\")\n",
    "os.makedirs(os.path.join(output_path), exist_ok=True)\n",
    "\n",
    "cs = b.get_configuration_space()\n",
    "\n",
    "history = regularized_evolution(\n",
    "    cycles=n_iters, population_size=pop_size, sample_size=sample_size)\n",
    "\n",
    "if benchmark == \"nas_cifar10a\" or benchmark == \"nas_cifar10b\":\n",
    "    res = b.get_results(ignore_invalid_configs=True)\n",
    "else:\n",
    "    res = b.get_results()\n",
    "\n",
    "fh = open(os.path.join(output_path, 'run_%d.json' % run_id), 'w')\n",
    "json.dump(res, fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
